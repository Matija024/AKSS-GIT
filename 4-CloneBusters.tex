The uniqueness of CloneBusters is the resignation of reliance on a Trusted Third Party since they are hard to find in real-life applications. To achieve this goal they implemented a channel (respectfully a cache set) for every enclave in which only his binary can communicate in. This communication is then monitored by CloneBusters and fed to a classification algorithm to detect clones of an instance i.e. enclave. \\
\\
\textbf{Clones} - If a second instance of an enclave is generated, it is set to be a clone if (i) they are loaded with the same binary and (ii) they run at the same time. (ii) is necessary since SGX itself can detect the clone if the clones run one at a time. Here the system relies on Monotonic Counters (MC) which will be incremented by an enclave to track its progress. The mode \textit{"inc-then-store"} is used which can be described as when data is stored, the index will be increased beforehand and saved as well to deliver validation. This validation is carried out once while storing the data so no index can be assigned to multiple data sets and second, if an enclave requests a data set it only accepts it if its counter is the same as the counter saved along with the data.
\\
\\
However, a vulnerability was discovered by the authors of CloneBusters while executing the \textit{"inc-then-store"} mode. Imagine one enclave E, its clone E', and a malicious OS that created that clone and is in control of the execution order of E and E'. Both enclaves will start with the same MC value (which is global) and loaded binary. In order to process Input \(I_1\), E increments MC once, however is then paused through the OS. The OS then feeds \(I_2\) to E' which also increments MC, leading MC to be +2. After that, the enclaves can proceed simultaneously since they will execute \textbf{Read(MC)} and receive the same value but arrive at different outputs which will be stored with the same index leading to a violation of the given rollback attack prevention from SGX. \\
Therefore CloneBusters developed a strategy to detect clones as they try to operate parallel to its enclave. The implementation of communication through already available cache sets enables CloneBusters to not rely on a TTP. This is accomplished by two phases which have to be executed, (1) the preparation phase and (2) the monitoring phase. The group of cache sets, i.e. the channel, is developed in (1) to enable phase (2) to monitor this channel where every instance with the same binary (the enclave and its clones) will put its data in, so a classification algorithm can check cache hits and misses to detect clones which will inevitably replace the data from the original enclave with its signed data.

\subsection{Preparation Phase (1)}
In order to assign cache sets to enclaves the creators of CloneBusters evaluated the physical addresses (16 Bits) of the system and concluded that these sets are best to be indexed by bits 6-15. This leaves a total of 16 cache sets which are used for a channel of an enclave. In the paper, they show that this is the perfect size for enclaves to detect the presence of clones.\\
After determining the right quantity, eviction sets have to be allocated to finalize the channels in which the enclaves will communicate in. The enclaves should have eviction sets where the memory is contiguous, however, the OS could assign non-contiguous memory. In order to avoid this violation, the creators developed an algorithm to create the eviction sets properly. The algorithm and its method of operation can be detailed in the paper~\cite{nfw}.

\subsection{Monitoring Phase (2)}
With the establishment of the eviction sets the enclaves can start operating. CloneBusters has to run continuously while a critical phase is executed (e.g. while incrementing and reading the MC), to provide optimal security. Before entering the \textit{"inc-then-store"} section, the enclave has to pre-fetch, the data to be monitored, into the cache set to provide expressive reliance on CloneBusters. \\
The monitoring is done by measuring the time to access data on the cache. Since the enclave has to fetch its data into the cache, it expects to receive a cache hit if it accesses the data. However, if a clone is running simultaneously it will replace the enclave's data with its own, so the enclave will detect a cache miss. This recorded time is then forwarded to a classification algorithm. With a pre-defined threshold of what time it takes to access either cache hits or cache misses, the algorithm can distinguish hits and misses and then determine if a clone is running. This information is then passed back to the enclave to take appropriate countermeasures like holding the execution of the enclave.\\
The authors of CloneBusters note that the cache sets are used by other applications as well. Therefore they have provided evidence, that if the caches are polluted by different applications, CloneBusters will still operate in the expected way.